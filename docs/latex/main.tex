\documentclass[a4paper, 12pt]{article}

\usepackage[english, portuguese]{babel}
\usepackage[hmargin=2cm,vmargin=2.5cm]{geometry}
\usepackage{amsmath}
\usepackage{hyperref}
\usepackage{graphicx}

\newcommand{\HRule}{\rule{\linewidth}{0.5mm}}

\newtheorem{definition}{Definição}
\newtheorem{theorem}{Teorema}

\begin{document}

\input{sections/title.tex}

\newpage 

\section*{Resumo}
\noindent
Algoritmos de aprendizado não supervisionado de métricas utilizam grafos como aproximações discretas para as variedades que representam a estrutura geométrica subjacente dos conjuntos de dados multivariados. Atualmente, a metodologia adotada pelos algoritmos tradicionais de aprendizado de variedades na ponderação das arestas desses grafos ainda é bastante rudimentar, uma vez que adota-se a distância Euclidiana como medida de similaridade. Porém, a distância Euclidiana é extrínseca à variedade em questão e não leva em consideração a noção de curvatura. Por essa razão, esse projeto de pesquisa visa propor métodos matematicamente originais, mais precisos e adequados para a caracterização da similaridade entre amostras vizinhas do grafo KNN. A ideia consiste em utilizar conceitos da geometria diferencial, como a curvatura, que é uma medida intrínseca, para ponderar arestas de caminhos mínimos em tais grafos, uma vez que eles representam aproximações para as verdadeiras distâncias geodésicas entre diferentes pontos pertencentes à variedade. Basicamente, a estratégia consiste em medir as variações dos espaços tangentes conforme nos movemos através de um caminho mínimo no grafo KNN. Com isso, espera-se melhorar o desempenho de diversos algoritmos utilizados na extração de características em problemas de classificação de padrões, como o PCA (\emph{Principal Component Analysis}), ISOMAP (\emph{Isometric Feature Mapping}) e LLE (\emph{Locally Linear Embedding}). Resultados preliminares com o algoritmo ISOMAP mostram um ganho significativo na acurácia da classificação de diversos conjuntos de dados reais em comparação com as versões tradicionais e outros métodos estado da arte, como t-SNE e UMAP. Além disso, espera-se incorporar os grafos baseados em curvatura (\emph{K-graphs}) em modelos para classificação de padrões e agrupamento de dados baseados em grafos.  

\section*{Abstract}
\noindent
Unsupervised metric learning algorithms use graphs as discrete approximations for the manifolds that represent the underlying geometric structure of multivariate data. At the moment, the usual methodology employed by these algorithms for building the KNN graph edges is quite elementary, since the Euclidean distante is the similarity measure. However, the Euclidean distance is extrinsic to the manifold and it does not take into account the intrinsic notion of curvature. For this reason, this research project aims to propose original and more suitable mathematical methods to characterize the similarity between neighboring samples in the KNN graph. The idea consists in the application of differential geometry concepts, such as the curvature, an intrinsic measure, to weight the edges of shortest paths in the graphs, since they represent discrete approximations to the true underlying geodesic distances between different points belonging to the manifold. Basically, our strategy is to measure the variation of the tangent space as we move along a shortest path in the KNN graph. With the proposed method, we expect to improve the performance of several feature extraction algorithms in pattern classification, such as PCA (\emph{Principal Component Analysis}), ISOMAP (\emph{Isometric Feature Mapping}) and LLE (\emph{Locally Linear Embedding}). Preliminary results with the ISOMAP algorithm show a significant gain in the classification accuracy of several real world datasets in comparison to their regular versions and other state-of-the-art methods, such as t-SNE and UMAP. Moreover, we intend to incorporate the proposed curvature based graphs (\emph{K-graphs}) in graph-based classification and clustering models.

\newpage

\section{Enunciado do problema}
test \cite{Seung,Brand,Cayton,Huo2007,Advances,Diffusion1}. test \cite{Isomap,Isomap_converg},  (LLE) \cite{LLE,LLE2,LLE3,LLE4, LLE5} test\cite{LapEig,SurveyLE}. 
\newpage 

\bibliographystyle{ieeetr}
\bibliography{mybib.bib}

\end{document}




